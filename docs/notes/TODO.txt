Done:
- Generate Dataset: Real spectra vs synthitic spectra
- Create Dataloader for spectra
- Create original CycleGAN for this data type
- Add TTUR
- Fix output of Discriminator (Reshape + Linear Layer)
- Add Wasserstein Loss + Spectral Normalization
    - Use a linear activation function in the output layer of the critic model (instead of sigmoid).
    - Use Wasserstein loss to train the critic and generator models that promote larger difference between scores for real and generated images.
    - Constrain critic model weights to a limited range after each mini batch update (e.g. [-0.01,0.01]).
    OR
    - Gradient Penalty
    - Update the critic model more times than the generator each iteration (e.g. 5).
- Setup Random Forest code
- Improve Loss visualization
- Spectral Normalization
- Convert matlab code to python (pydicom)
- Improve dicom2matlab code
- Fix loss

- Create Paired Dataset for validation only!
- Entropy Loss
- Create baselines with paired dataset
- Fix loss plots 
- Create Dataset without noise
- Update README
- Switch to simple dataset


- Only use small kernels for entropy loss (2,3,4)
- Test entropy loss + identity loss
- Crop range to 300-800
- Use pearson coefficient for validation metric
- Refine network architecture image
- Make magnitude an option for the dataloader
USCF:
- Use cre map for selection of voxels
- Throw away cre=0 (outliers)
- Calculate cho/cre and NAA/cre
- Compare Data distributions (also across patients)
- test entropy + identity for cropped

########
- Check LCM distributions
- Check on Auto-encoder (Talk with Prof. Menze)
- Get MLP Regressor working
- Improve baseline creation
- Check RF performance for univariate regression
- Compare inner feature representations before and after transformation with L1 loss
- Compare inner feature representations of before-before and after-after
- improve smooth loss (sliding kernel=5)


TODO:

- Use new borders for synthetic data generation (+- 0.5 for cho, naa)
- raytune: Increase duration for reportss + max iter

- RMSE for MLP

- CBAM module

- Create & train Auto-encoder
- Integrate Auto-Encoder to CycleGAN
- Reasons for CycleGAN:
    - CycleGAN as preprocessing step for other methods
    - We can compare different methods on the same domain


docs:
- Update READMEs
- Add UCSF description